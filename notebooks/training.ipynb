{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients_path = \"../data/nutrition5k_dataset_nosides/processed/ingredients_metadata.csv\"\n",
    "dishes_info_path = \"../data/nutrition5k_dataset_nosides/processed/dishes_info.csv\"\n",
    "dish_ids_path = \"../data/nutrition5k_dataset_nosides/dish_ids/splits/rgb_train_ids.txt\"\n",
    "img_dir = \"../data/nutrition5k_dataset_nosides/imagery/realsense_overhead/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([508, 122,  26, 524,  94,  23, 189,  54,  29, 328, 291, 520, 161,\n",
       "       462, 525, 312, 513,  43, 448, 514, 152,  45,   6, 116, 471,  31,\n",
       "       347, 453,  32, 523, 526, 515,  14, 367, 349,   8, 192, 440, 128,\n",
       "       437, 335, 433,   7,  21, 244,  36, 148, 518, 112,  27, 510,  13,\n",
       "       517, 201,  46, 126, 124, 133, 332, 540, 257, 434,  11,  92, 341,\n",
       "        25,  74, 485, 203,  77,   5,  73, 180, 380, 535, 528,  15, 392,\n",
       "        10,  72,  38,  30,   1, 121, 521, 516,  28, 475,  37, 251,  47,\n",
       "        52, 320,  12, 529,  49, 527, 205, 522, 441, 519, 428, 194,  33,\n",
       "        80, 213, 511,  39, 538, 539,  34, 472,  16, 532, 155, 187, 306,\n",
       "       140, 473, 153,   4, 377, 275, 179, 534, 457, 162,  35, 507,   2,\n",
       "       512,  42,  82, 129,  58,  41, 421, 458, 338, 545, 543, 502, 484,\n",
       "       238, 495, 264,  50, 541,  70, 531,   3,  59, 425, 166, 141,  95,\n",
       "       498,  60, 402, 294,  40, 105, 357,  81,  67, 337, 319, 415, 262,\n",
       "       423, 364, 297, 113, 342, 372, 455, 273, 463, 102,   9,  19, 409,\n",
       "       542, 137, 154, 200, 318, 221, 243, 537, 536, 245, 413, 208, 177,\n",
       "       196, 546,  17, 375, 287,  98, 281, 442,  76, 254, 549, 551, 279,\n",
       "       456,  51, 314, 371, 174, 321, 555, 159, 214, 252, 359, 506, 466,\n",
       "        87, 228, 481, 101, 168,  18, 185, 385, 530, 110, 220, 136,  89,\n",
       "       444,  55, 249, 217,  57, 494, 117, 393, 550, 100, 476, 553, 487])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(ingredients_path)\n",
    "labels = df[\"ingredient_id\"].unique()\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IngredientDataset(Dataset):\n",
    "    def __init__(self, img_dir: str, ingredients_path: str, dish_info_path: str):\n",
    "        self.img_dir = img_dir\n",
    "\n",
    "        self.ingredients_df = pd.read_csv(ingredients_path)\n",
    "        self.dish_info_df = pd.read_csv(dish_info_path)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dish_info_df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        dish = self.dish_info_df.iloc[index]\n",
    "        dish_id = dish[0]\n",
    "\n",
    "        ingredient_ids = self.ingredients_df[self.ingredients_df[\"dish_id\"] == dish_id][\"ingredient_id\"].values\n",
    "        label_tensor = torch.FloatTensor(ingredient_ids)\n",
    "        \n",
    "        dish_weight = dish[2]\n",
    "        weight_in_g_tensor = torch.FloatTensor([dish_weight])\n",
    "\n",
    "        img_path = os.path.join(self.img_dir, dish_id, \"rgb.png\")\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img_tensor = torch.FloatTensor(img)[None, :, :]\n",
    "\n",
    "        return img_tensor, label_tensor, weight_in_g_tensor\n",
    "\n",
    "    def get_num_of_classes(self) -> int:\n",
    "        return self.label_binarizer.classes_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = IngredientDataset(img_dir, ingredients_path, dishes_info_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6b/g5x_vfn514d15rfps5h6pz640000gp/T/ipykernel_6621/2608603742.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  dish_id = dish[0]\n",
      "/var/folders/6b/g5x_vfn514d15rfps5h6pz640000gp/T/ipykernel_6621/2608603742.py:18: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  dish_weight = dish[2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[[114., 119., 122.],\n",
       "           [116., 121., 124.],\n",
       "           [116., 122., 122.],\n",
       "           ...,\n",
       "           [121., 127., 134.],\n",
       "           [130., 130., 140.],\n",
       "           [134., 134., 144.]],\n",
       " \n",
       "          [[114., 119., 122.],\n",
       "           [116., 121., 124.],\n",
       "           [116., 122., 122.],\n",
       "           ...,\n",
       "           [121., 127., 134.],\n",
       "           [128., 130., 140.],\n",
       "           [131., 133., 143.]],\n",
       " \n",
       "          [[112., 120., 122.],\n",
       "           [114., 122., 124.],\n",
       "           [116., 121., 124.],\n",
       "           ...,\n",
       "           [121., 127., 134.],\n",
       "           [128., 130., 140.],\n",
       "           [131., 133., 143.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[105., 112., 116.],\n",
       "           [102., 109., 113.],\n",
       "           [102., 110., 112.],\n",
       "           ...,\n",
       "           [129., 127., 133.],\n",
       "           [132., 129., 138.],\n",
       "           [136., 133., 142.]],\n",
       " \n",
       "          [[ 95., 103., 110.],\n",
       "           [100., 108., 115.],\n",
       "           [102., 109., 113.],\n",
       "           ...,\n",
       "           [129., 126., 135.],\n",
       "           [133., 129., 140.],\n",
       "           [136., 132., 143.]],\n",
       " \n",
       "          [[ 94., 102., 109.],\n",
       "           [100., 108., 115.],\n",
       "           [102., 108., 115.],\n",
       "           ...,\n",
       "           [129., 125., 136.],\n",
       "           [133., 129., 140.],\n",
       "           [136., 132., 143.]]]]),\n",
       " tensor([508., 122.,  26., 524.,  94.,  23., 189.,  54.,  29., 328., 291., 520.,\n",
       "         161., 462., 525., 312., 513.]),\n",
       " tensor([193.]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
