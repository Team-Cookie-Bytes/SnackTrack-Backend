{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients_path = \"../data/nutrition5k_dataset_nosides/metadata/ingredients_metadata.csv\"\n",
    "dish_metadata_path = \"test.csv\" # \"../data/nutrition5k_dataset_nosides/metadata/dish_metadata_cafe1.csv\"\n",
    "dish_ids_path = \"../data/nutrition5k_dataset_nosides/dish_ids/dish_ids_all.txt\"\n",
    "img_dir = \"../data/nutrition5k_dataset_nosides/imagery/realsense_overhead/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes: 555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(ingredients_path)\n",
    "labels = df[\"id\"]\n",
    "\n",
    "label_binarizer = MultiLabelBinarizer()\n",
    "label_binarizer.fit([labels.to_list()])\n",
    "\n",
    "num_of_classes = label_binarizer.classes_.shape[0]\n",
    "print(\"number of classes:\", num_of_classes)\n",
    "label_binarizer.transform([[2, 3]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_ingredient_id(name: str) -> int:\n",
    "    return int(name.split('_')[1])\n",
    "\n",
    "parse_ingredient_id(\"ingr_0000000008\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[508, 122, 26, 524, 94, 23, 189, 54, 29, 328, 291, 520, 161, 462, 525, 312, 513]\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/18/mk89nqqd4t1738cgptywpmw00000gn/T/ipykernel_7622/2861585244.py:14: DtypeWarning: Columns (1,2,3,4,5,8,9,10,11,12,15,16,17,18,19,22,23,24,25,26,29,30,31,32,33,36,37,38,39,40,43,44,45,46,47,50,51,52,53,54,57,58,59,60,61,64,65,66,67,68,71,72,73,74,75,78,79,80,81,82,85,86,87,88,89,92,93,94,95,96,99,100,101,102,103,106,107,108,109,110,113,114,115,116,117,120,121,122,123,124,127,128,129,130,131,134,135,136,137,138,141,142,143,144,145,148,149,150,151,152,155,156,157,158,159,162,163,164,165,166,169,170,171,172,173,176,177,178,179,180,183,184,185,186,187,190,191,192,193,194,197,198,199,200,201,204,205,206,207,208,211,212,213,214,215,218,219,220,221,222,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"test2.csv\", header=None)\n"
     ]
    }
   ],
   "source": [
    "def get_ingredient_ids_from_row(row):\n",
    "    ingredient_ids = []\n",
    "\n",
    "    # Iterate over each ingredient in the row\n",
    "    # We start from column 7 (0-indexed), and increment by 7 for each ingredient\n",
    "    for i in range(6, len(row), 7):\n",
    "        # Check if ingredient id is not missing\n",
    "        if pd.notnull(row.iloc[i]):\n",
    "            # Get the ingredient id and remove any leading zeros\n",
    "            ingredient_ids.append(parse_ingredient_id(row.iloc[i]))\n",
    "    \n",
    "    return ingredient_ids\n",
    "\n",
    "df = pd.read_csv(\"test2.csv\", header=None)\n",
    "df.head()\n",
    "row = df.iloc[1]\n",
    "print(get_ingredient_ids_from_row(row))\n",
    "print(len(get_ingredient_ids_from_row(row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IngredientDataset(Dataset):\n",
    "    def __init__(self, img_dir: str, ingredients_path: str, dish_metadata_path: str, dish_ids_path):\n",
    "        self.img_dir = img_dir\n",
    "        self.ingredients_path = ingredients_path\n",
    "        self.dish_metadata_path = dish_metadata_path\n",
    "        self.dish_ids_path = dish_ids_path\n",
    "\n",
    "        self.ingredients_df = pd.read_csv(ingredients_path)\n",
    "        self.label_binarizer = MultiLabelBinarizer()   \n",
    "        self.label_binarizer.fit([self.ingredients_df[\"id\"].to_list()])\n",
    "\n",
    "        self.dish_metadata_df = pd.read_csv(dish_metadata_path)\n",
    "        self.dish_ids_df = pd.read_csv(dish_ids_path, header=None)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.dish_ids_df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        dish_id = self.dish_ids_df.iloc[index, 0]\n",
    "\n",
    "        label = get_ingredient_ids_from_row(self.dish_metadata_path)[self.dish_metadata_path.iloc[:, 0] == dish_id]\n",
    "        name = self.df.iat[index, 0]\n",
    "\n",
    "        img_path = os.path.join(self.img_dir, name)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img_tensor = torch.FloatTensor(img)[None, :, :]\n",
    "\n",
    "        label_encoded = self.label_binarizer.transform([label])[0]\n",
    "        label_tensor = torch.FloatTensor(label_encoded)\n",
    "        \n",
    "        return img_tensor, label_tensor\n",
    "\n",
    "    def get_num_of_classes(self) -> int:\n",
    "        return self.label_binarizer.classes_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = IngredientDataset(img_dir, ingredients_path, dish_metadata_path, dish_ids_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
